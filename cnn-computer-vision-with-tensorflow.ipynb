{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-31T13:33:27.181676Z","iopub.execute_input":"2021-12-31T13:33:27.182556Z","iopub.status.idle":"2021-12-31T13:33:28.166481Z","shell.execute_reply.started":"2021-12-31T13:33:27.182511Z","shell.execute_reply":"2021-12-31T13:33:28.165706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Making a Dense Net CNN with Tensorflow to make Classification of Yoga Poses\nI will be making a Multi Class Image Classification Problem","metadata":{}},{"cell_type":"code","source":"# Initially we will build some Binary Classification for each Asanas\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport re\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:28.169484Z","iopub.execute_input":"2021-12-31T13:33:28.169689Z","iopub.status.idle":"2021-12-31T13:33:33.206331Z","shell.execute_reply.started":"2021-12-31T13:33:28.169663Z","shell.execute_reply":"2021-12-31T13:33:33.205477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"End to End Model Building with Input Layer -->  Convolution Layer --> Hidden Activation --> Pooling Layer --> Connected Layer --> Output Activation and Layer\nWith multiple Pooling and Convolution Layers","metadata":{}},{"cell_type":"code","source":"# EDA\n!ls ../input/yoga-pose-image-classification-dataset/dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:33.20772Z","iopub.execute_input":"2021-12-31T13:33:33.208127Z","iopub.status.idle":"2021-12-31T13:33:33.978228Z","shell.execute_reply.started":"2021-12-31T13:33:33.208091Z","shell.execute_reply":"2021-12-31T13:33:33.977238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding out the Number of Asanas\nfor dirpath,dirnames,filenames in os.walk(\"../input/yoga-pose-image-classification-dataset/dataset\"):\n    print(f\"There are {len(dirnames)} asanas in the '{dirpath}'\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:33.981448Z","iopub.execute_input":"2021-12-31T13:33:33.981769Z","iopub.status.idle":"2021-12-31T13:33:34.046665Z","shell.execute_reply.started":"2021-12-31T13:33:33.981705Z","shell.execute_reply":"2021-12-31T13:33:34.045974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA  for any Asana\nanantasana=len(os.listdir(\"../input/yoga-pose-image-classification-dataset/dataset/anantasana\"))\nanantasana\n# 43 Images so we wont be splitting it to Train Test and Rather Make Predictions of Custom Images\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.049673Z","iopub.execute_input":"2021-12-31T13:33:34.049895Z","iopub.status.idle":"2021-12-31T13:33:34.057567Z","shell.execute_reply.started":"2021-12-31T13:33:34.04987Z","shell.execute_reply":"2021-12-31T13:33:34.056794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\ndata_dir=pathlib.Path(\"../input/yoga-pose-image-classification-dataset/dataset\")\nclass_names=np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\nclass_names\n# Creating an array of Classes for Predictions\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.059392Z","iopub.execute_input":"2021-12-31T13:33:34.05975Z","iopub.status.idle":"2021-12-31T13:33:34.072973Z","shell.execute_reply.started":"2021-12-31T13:33:34.059622Z","shell.execute_reply":"2021-12-31T13:33:34.07196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir=\"../input/yoga-pose-image-classification-dataset/dataset\"\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.074847Z","iopub.execute_input":"2021-12-31T13:33:34.075444Z","iopub.status.idle":"2021-12-31T13:33:34.081339Z","shell.execute_reply.started":"2021-12-31T13:33:34.075415Z","shell.execute_reply":"2021-12-31T13:33:34.080447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Pre Processing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# Reescaling the Data\ntrain_datagen=  ImageDataGenerator(rescale=1/255.)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.082808Z","iopub.execute_input":"2021-12-31T13:33:34.083265Z","iopub.status.idle":"2021-12-31T13:33:34.218848Z","shell.execute_reply.started":"2021-12-31T13:33:34.083208Z","shell.execute_reply":"2021-12-31T13:33:34.218144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the Data from the dirs and turnit into Batches\ntrain_data=train_datagen.flow_from_directory(train_dir,target_size=(224,224),batch_size=32,class_mode=\"categorical\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.222093Z","iopub.execute_input":"2021-12-31T13:33:34.222685Z","iopub.status.idle":"2021-12-31T13:33:34.644707Z","shell.execute_reply.started":"2021-12-31T13:33:34.222646Z","shell.execute_reply":"2021-12-31T13:33:34.643978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the Libraries\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.647352Z","iopub.execute_input":"2021-12-31T13:33:34.647606Z","iopub.status.idle":"2021-12-31T13:33:34.653315Z","shell.execute_reply.started":"2021-12-31T13:33:34.647573Z","shell.execute_reply":"2021-12-31T13:33:34.652467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a CNN Model for Training \n# Creating the Model\nmodel=Sequential([Conv2D(10,3,input_shape=(224,224,3)),\n                  Activation(activation=\"relu\"),\n                  Conv2D(10,3,activation=\"relu\"),\n                  MaxPool2D(),\n                  Conv2D(10,3,activation=\"relu\"),\n                  Conv2D(10,3,activation=\"relu\"),\n                  MaxPool2D(),\n                  Flatten(),\n                  Dense(107,activation='softmax')\n                 ])\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\"])\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:34.654812Z","iopub.execute_input":"2021-12-31T13:33:34.655405Z","iopub.status.idle":"2021-12-31T13:33:37.020232Z","shell.execute_reply.started":"2021-12-31T13:33:34.655366Z","shell.execute_reply":"2021-12-31T13:33:37.019297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Over Fitting the Model to the Dataset\nhistory=model.fit(train_data,epochs=10,steps_per_epoch=len(train_data))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:33:37.021593Z","iopub.execute_input":"2021-12-31T13:33:37.022388Z","iopub.status.idle":"2021-12-31T13:40:22.783222Z","shell.execute_reply.started":"2021-12-31T13:33:37.022348Z","shell.execute_reply":"2021-12-31T13:40:22.782334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the Model\ntestdata=\"../input/testdata1\"\nfrom PIL import Image\ntest_data=train_datagen.flow_from_directory(testdata,target_size=(224,224),class_mode=\"categorical\")\n# np_img = np_img[np.newaxis,:,:]\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:40:22.78476Z","iopub.execute_input":"2021-12-31T13:40:22.785015Z","iopub.status.idle":"2021-12-31T13:40:22.894147Z","shell.execute_reply.started":"2021-12-31T13:40:22.784978Z","shell.execute_reply":"2021-12-31T13:40:22.893411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred=model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:40:22.895618Z","iopub.execute_input":"2021-12-31T13:40:22.895905Z","iopub.status.idle":"2021-12-31T13:40:23.066961Z","shell.execute_reply.started":"2021-12-31T13:40:22.895869Z","shell.execute_reply":"2021-12-31T13:40:23.066195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.image as mpimg\n# Create a function to import and image and resize it to be able to be used with our model\ndef load_and_prep_image(filename, img_shape=224):\n \n  # Read in the image\n  img = tf.io.read_file(filename)\n  # Decode the read file into a tensor\n  img = tf.image.decode_image(img)\n  # Resize the image\n  img = tf.image.resize(img, size=[img_shape, img_shape])\n  # Rescale the image (get all values between 0 and 1)\n  img = img/255.\n  return img","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:40:23.068278Z","iopub.execute_input":"2021-12-31T13:40:23.070046Z","iopub.status.idle":"2021-12-31T13:40:23.074624Z","shell.execute_reply.started":"2021-12-31T13:40:23.070012Z","shell.execute_reply":"2021-12-31T13:40:23.073956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_and_plot(model, test_img, class_names=class_names):\n \n  # Import the target image and preprocess it\n#   img = load_and_prep_image(filename)\n\n  # Make a prediction\n  pred = model.predict(tf.expand_dims(test_img, axis=0))\n\n  # Add in logic for multi-class & get pred_class name\n  if len(pred[0]) > 1:\n    pred_class = class_names[tf.argmax(pred[0])]\n  else:\n    pred_class = class_names[int(tf.round(pred[0]))]\n\n  # Plot the image and predicted class\n  plt.imshow(img)\n  plt.title(f\"Prediction: {pred_class}\")\n  plt.axis(False);\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:40:23.075902Z","iopub.execute_input":"2021-12-31T13:40:23.07662Z","iopub.status.idle":"2021-12-31T13:40:23.089754Z","shell.execute_reply.started":"2021-12-31T13:40:23.07658Z","shell.execute_reply":"2021-12-31T13:40:23.088944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_and_plot(model=model,\n              test_img=test_data,\n              class_names=class_names)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T13:40:23.090962Z","iopub.execute_input":"2021-12-31T13:40:23.091271Z"},"trusted":true},"execution_count":null,"outputs":[]}]}