{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-13T11:56:47.481504Z","iopub.execute_input":"2022-03-13T11:56:47.481843Z","iopub.status.idle":"2022-03-13T11:56:47.512166Z","shell.execute_reply.started":"2022-03-13T11:56:47.481761Z","shell.execute_reply":"2022-03-13T11:56:47.511194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recommender Systems","metadata":{}},{"cell_type":"markdown","source":"## Types of Recommender Systems\n#### Content Based Recommender Systems\n#### Collaborative Filtering based Systems\n#### Hybrid Recommender Systems","metadata":{}},{"cell_type":"code","source":"# Example of Content Based Filtering Recommender System\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:47.513284Z","iopub.execute_input":"2022-03-13T11:56:47.513723Z","iopub.status.idle":"2022-03-13T11:56:48.475189Z","shell.execute_reply.started":"2022-03-13T11:56:47.513691Z","shell.execute_reply":"2022-03-13T11:56:48.474095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the Data and  placing it into a dataframe\nmovies_df=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_movies.csv')\ncredits_df=pd.read_csv('../input/tmdb-movie-metadata/tmdb_5000_credits.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:48.476694Z","iopub.execute_input":"2022-03-13T11:56:48.476989Z","iopub.status.idle":"2022-03-13T11:56:49.333178Z","shell.execute_reply.started":"2022-03-13T11:56:48.476956Z","shell.execute_reply":"2022-03-13T11:56:49.332184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Examining the Data\nmovies_df.head(10)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-13T11:56:49.335733Z","iopub.execute_input":"2022-03-13T11:56:49.336102Z","iopub.status.idle":"2022-03-13T11:56:49.369325Z","shell.execute_reply.started":"2022-03-13T11:56:49.336058Z","shell.execute_reply":"2022-03-13T11:56:49.368437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Datatypes of the Features\nmovies_df.dtypes\n# movies_df.size\n# A lof of them are Object like JSON","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.370441Z","iopub.execute_input":"2022-03-13T11:56:49.370673Z","iopub.status.idle":"2022-03-13T11:56:49.378265Z","shell.execute_reply.started":"2022-03-13T11:56:49.370645Z","shell.execute_reply":"2022-03-13T11:56:49.377355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Examining the Credits\ncredits_df.head()\n# credits_df.size","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.379311Z","iopub.execute_input":"2022-03-13T11:56:49.379627Z","iopub.status.idle":"2022-03-13T11:56:49.397158Z","shell.execute_reply.started":"2022-03-13T11:56:49.379587Z","shell.execute_reply":"2022-03-13T11:56:49.396219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we must merge the dataframe to get one common dataframe\nmovies_df=movies_df.merge(credits_df,on='title')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.398548Z","iopub.execute_input":"2022-03-13T11:56:49.398791Z","iopub.status.idle":"2022-03-13T11:56:49.43691Z","shell.execute_reply.started":"2022-03-13T11:56:49.398764Z","shell.execute_reply":"2022-03-13T11:56:49.436041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we can see that the Dataframes have been merged\nmovies_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.440252Z","iopub.execute_input":"2022-03-13T11:56:49.440489Z","iopub.status.idle":"2022-03-13T11:56:49.445771Z","shell.execute_reply.started":"2022-03-13T11:56:49.440461Z","shell.execute_reply":"2022-03-13T11:56:49.444989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.447167Z","iopub.execute_input":"2022-03-13T11:56:49.447495Z","iopub.status.idle":"2022-03-13T11:56:49.480255Z","shell.execute_reply.started":"2022-03-13T11:56:49.447455Z","shell.execute_reply":"2022-03-13T11:56:49.479556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For recommendation systems it is essential to create tags\n\n# So for any dataset we have to examine which of the features are useful for creating tags and which are not\n\n# So we will list the Columns that are essential and the Columns not Listed will be dropped off\n\n# All of the features that may influence a viewers decision are kept \n\n# 1) Genres\n# 2) id\n# 3) Keywords\n# 4) Title\n# 5) Overview\n# 6) Cast \n# 7) Crew\n\n# Language is dropped as here it is highly highly skewed in favour of English\n# Some other features like Production House, Revenue, Release Date, Vote average, vote count can be an important factor\n# But we are keeping the approach very crude and so we will avoid the Numeric Values\n\n#Dropping the rest of the Columns\n\nmovies_df=movies_df[['genres','movie_id','title','overview','keywords','cast','crew','vote_average','vote_count','popularity','revenue']]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.482672Z","iopub.execute_input":"2022-03-13T11:56:49.483129Z","iopub.status.idle":"2022-03-13T11:56:49.494717Z","shell.execute_reply.started":"2022-03-13T11:56:49.483095Z","shell.execute_reply":"2022-03-13T11:56:49.493938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-examing the Data\nmovies_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.496006Z","iopub.execute_input":"2022-03-13T11:56:49.496451Z","iopub.status.idle":"2022-03-13T11:56:49.515822Z","shell.execute_reply.started":"2022-03-13T11:56:49.496415Z","shell.execute_reply":"2022-03-13T11:56:49.515142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Cleaning, Processing, Imputing steps\nmovies_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.517009Z","iopub.execute_input":"2022-03-13T11:56:49.517463Z","iopub.status.idle":"2022-03-13T11:56:49.529398Z","shell.execute_reply.started":"2022-03-13T11:56:49.51743Z","shell.execute_reply":"2022-03-13T11:56:49.528761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the 3 Null Values in the Overview columns\nmovies_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.530681Z","iopub.execute_input":"2022-03-13T11:56:49.531071Z","iopub.status.idle":"2022-03-13T11:56:49.54509Z","shell.execute_reply.started":"2022-03-13T11:56:49.53103Z","shell.execute_reply":"2022-03-13T11:56:49.544287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checkinng for Duplicates\nmovies_df.duplicated().sum()\n# No Duplicates and so it is good to go","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.546462Z","iopub.execute_input":"2022-03-13T11:56:49.547034Z","iopub.status.idle":"2022-03-13T11:56:49.654252Z","shell.execute_reply.started":"2022-03-13T11:56:49.546997Z","shell.execute_reply":"2022-03-13T11:56:49.653387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df.iloc[0].genres","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.655235Z","iopub.execute_input":"2022-03-13T11:56:49.656Z","iopub.status.idle":"2022-03-13T11:56:49.662371Z","shell.execute_reply.started":"2022-03-13T11:56:49.655955Z","shell.execute_reply":"2022-03-13T11:56:49.661508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\ndef convertdicttolist(obj):\n    list1=[]\n    for i in ast.literal_eval(obj):\n        list1.append(i['name'])\n    return list1\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.663471Z","iopub.execute_input":"2022-03-13T11:56:49.663665Z","iopub.status.idle":"2022-03-13T11:56:49.673593Z","shell.execute_reply.started":"2022-03-13T11:56:49.663642Z","shell.execute_reply":"2022-03-13T11:56:49.672692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df['genres']=movies_df['genres'].apply(convertdicttolist)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.674906Z","iopub.execute_input":"2022-03-13T11:56:49.675269Z","iopub.status.idle":"2022-03-13T11:56:49.817637Z","shell.execute_reply.started":"2022-03-13T11:56:49.675231Z","shell.execute_reply":"2022-03-13T11:56:49.816744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying this to all the Keywords, Cast and Crew\nmovies_df['keywords']=movies_df['keywords'].apply(convertdicttolist)\nmovies_df['cast']=movies_df['cast'].apply(convertdicttolist)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:49.819128Z","iopub.execute_input":"2022-03-13T11:56:49.81961Z","iopub.status.idle":"2022-03-13T11:56:52.959816Z","shell.execute_reply.started":"2022-03-13T11:56:49.819577Z","shell.execute_reply":"2022-03-13T11:56:52.958894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Checking the Final Output\nmovies_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:52.960962Z","iopub.execute_input":"2022-03-13T11:56:52.9612Z","iopub.status.idle":"2022-03-13T11:56:52.983416Z","shell.execute_reply.started":"2022-03-13T11:56:52.961173Z","shell.execute_reply":"2022-03-13T11:56:52.982555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we also want to limit the Number of entries for a feature\nmovies_df.iloc[0].cast\n# So qw do not need such a humongous cast and only need the top 3-4 of them","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-13T11:56:52.985306Z","iopub.execute_input":"2022-03-13T11:56:52.986017Z","iopub.status.idle":"2022-03-13T11:56:52.997506Z","shell.execute_reply.started":"2022-03-13T11:56:52.985971Z","shell.execute_reply":"2022-03-13T11:56:52.996696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So now we will reduce the Number of entries in the Cast to 3 Only\ndef getTop3(list):\n    counter=0\n    listnew=[]\n    for i in list:\n        if(counter<3):\n            listnew.append(i)\n        counter=counter+1\n    return listnew","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:52.998652Z","iopub.execute_input":"2022-03-13T11:56:52.99889Z","iopub.status.idle":"2022-03-13T11:56:53.00947Z","shell.execute_reply.started":"2022-03-13T11:56:52.998844Z","shell.execute_reply":"2022-03-13T11:56:53.008789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df['cast']=movies_df['cast'].apply(getTop3)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:53.010464Z","iopub.execute_input":"2022-03-13T11:56:53.011079Z","iopub.status.idle":"2022-03-13T11:56:53.046609Z","shell.execute_reply.started":"2022-03-13T11:56:53.011042Z","shell.execute_reply":"2022-03-13T11:56:53.045921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df['cast']","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:53.047705Z","iopub.execute_input":"2022-03-13T11:56:53.048062Z","iopub.status.idle":"2022-03-13T11:56:53.056257Z","shell.execute_reply.started":"2022-03-13T11:56:53.048033Z","shell.execute_reply":"2022-03-13T11:56:53.055296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It gets a Slightly trickier for crew as we would like to get the Directors,\nmovies_df['crew'][0]\n# We are only Interested in Director and Producer so we will cut off the rest ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-13T11:56:53.057516Z","iopub.execute_input":"2022-03-13T11:56:53.058084Z","iopub.status.idle":"2022-03-13T11:56:53.068656Z","shell.execute_reply.started":"2022-03-13T11:56:53.05805Z","shell.execute_reply":"2022-03-13T11:56:53.067726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the Director and Producer\ndef fetchDandP(obj):\n    DPlist=[]\n    for i in ast.literal_eval(obj):\n        if(i['job']=='Director' or i['job']=='Producer'):\n            DPlist.append(i['name'])\n    return DPlist","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:53.069737Z","iopub.execute_input":"2022-03-13T11:56:53.07005Z","iopub.status.idle":"2022-03-13T11:56:53.081165Z","shell.execute_reply.started":"2022-03-13T11:56:53.070018Z","shell.execute_reply":"2022-03-13T11:56:53.07989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df['crew']=movies_df['crew'].apply(fetchDandP)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:53.082527Z","iopub.execute_input":"2022-03-13T11:56:53.082915Z","iopub.status.idle":"2022-03-13T11:56:56.331198Z","shell.execute_reply.started":"2022-03-13T11:56:53.082846Z","shell.execute_reply":"2022-03-13T11:56:56.330261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df.iloc[0].crew","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.332439Z","iopub.execute_input":"2022-03-13T11:56:56.332783Z","iopub.status.idle":"2022-03-13T11:56:56.339593Z","shell.execute_reply.started":"2022-03-13T11:56:56.332741Z","shell.execute_reply":"2022-03-13T11:56:56.338806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will split the Overview words into a list as well\nmovies_df['overview']=movies_df['overview'].apply(lambda x:x.split())","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.343924Z","iopub.execute_input":"2022-03-13T11:56:56.344166Z","iopub.status.idle":"2022-03-13T11:56:56.381837Z","shell.execute_reply.started":"2022-03-13T11:56:56.344137Z","shell.execute_reply":"2022-03-13T11:56:56.380886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As we can see that the Overview has been splitted into a List\nmovies_df.iloc[0:10].overview","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.383364Z","iopub.execute_input":"2022-03-13T11:56:56.383592Z","iopub.status.idle":"2022-03-13T11:56:56.392513Z","shell.execute_reply.started":"2022-03-13T11:56:56.383566Z","shell.execute_reply":"2022-03-13T11:56:56.391948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now since we have everything in lists we will have to concatenate the lists\n# Before that we will have to concat the Strings with spaces and so we will have to apply transformations\nmovies_df['genres']=movies_df['genres'].apply(lambda x:[i.replace(\" \",\"\") for i in x])","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.393469Z","iopub.execute_input":"2022-03-13T11:56:56.394063Z","iopub.status.idle":"2022-03-13T11:56:56.412912Z","shell.execute_reply.started":"2022-03-13T11:56:56.394028Z","shell.execute_reply":"2022-03-13T11:56:56.412028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_df['keywords']=movies_df['keywords'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\nmovies_df['cast']=movies_df['cast'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\nmovies_df['crew']=movies_df['crew'].apply(lambda x:[i.replace(\" \",\"\") for i in x])","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.414379Z","iopub.execute_input":"2022-03-13T11:56:56.415374Z","iopub.status.idle":"2022-03-13T11:56:56.45714Z","shell.execute_reply.started":"2022-03-13T11:56:56.415324Z","shell.execute_reply":"2022-03-13T11:56:56.456274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We can see that the transformation has been applied and the words have been joined\nmovies_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.458431Z","iopub.execute_input":"2022-03-13T11:56:56.458763Z","iopub.status.idle":"2022-03-13T11:56:56.492343Z","shell.execute_reply.started":"2022-03-13T11:56:56.458722Z","shell.execute_reply":"2022-03-13T11:56:56.491537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new columns tags and then add all the columns to that column\nmovies_df['tags']=movies_df['overview']+movies_df['genres']+movies_df['cast']+movies_df['crew']+movies_df['keywords']","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.493602Z","iopub.execute_input":"2022-03-13T11:56:56.493923Z","iopub.status.idle":"2022-03-13T11:56:56.687398Z","shell.execute_reply.started":"2022-03-13T11:56:56.493885Z","shell.execute_reply":"2022-03-13T11:56:56.686692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a New dataframe with a only the required features\nnew_movies_df=movies_df[['movie_id','title','tags','vote_average','popularity']]","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.688601Z","iopub.execute_input":"2022-03-13T11:56:56.688831Z","iopub.status.idle":"2022-03-13T11:56:56.694593Z","shell.execute_reply.started":"2022-03-13T11:56:56.688806Z","shell.execute_reply":"2022-03-13T11:56:56.693817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_movies_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.695792Z","iopub.execute_input":"2022-03-13T11:56:56.696023Z","iopub.status.idle":"2022-03-13T11:56:56.718694Z","shell.execute_reply.started":"2022-03-13T11:56:56.695997Z","shell.execute_reply":"2022-03-13T11:56:56.718121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we will convert the List of tags into Strings for better Usability\nnew_movies_df['tags']=new_movies_df['tags'].apply(lambda x: \" \".join(x))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.719634Z","iopub.execute_input":"2022-03-13T11:56:56.720165Z","iopub.status.idle":"2022-03-13T11:56:56.737966Z","shell.execute_reply.started":"2022-03-13T11:56:56.720134Z","shell.execute_reply":"2022-03-13T11:56:56.737241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting everything to lowercase\nnew_movies_df['tags']=new_movies_df['tags'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.738989Z","iopub.execute_input":"2022-03-13T11:56:56.739745Z","iopub.status.idle":"2022-03-13T11:56:56.752689Z","shell.execute_reply.started":"2022-03-13T11:56:56.739711Z","shell.execute_reply":"2022-03-13T11:56:56.751758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Vectorization","metadata":{}},{"cell_type":"markdown","source":"### Applying stemming to get a cleaner corpus","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nps=PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:56.754233Z","iopub.execute_input":"2022-03-13T11:56:56.754538Z","iopub.status.idle":"2022-03-13T11:56:57.456656Z","shell.execute_reply.started":"2022-03-13T11:56:56.754496Z","shell.execute_reply":"2022-03-13T11:56:57.45569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stem(text):\n    y=[]\n    for i in text.split():\n        y.append(ps.stem(i))\n    string=\" \".join(y)\n    return string","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:57.457807Z","iopub.execute_input":"2022-03-13T11:56:57.458075Z","iopub.status.idle":"2022-03-13T11:56:57.463421Z","shell.execute_reply.started":"2022-03-13T11:56:57.458046Z","shell.execute_reply":"2022-03-13T11:56:57.462522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stemming the Column\nnew_movies_df['tags']=new_movies_df['tags'].apply(stem)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:56:57.464457Z","iopub.execute_input":"2022-03-13T11:56:57.464705Z","iopub.status.idle":"2022-03-13T11:57:02.855724Z","shell.execute_reply.started":"2022-03-13T11:56:57.464678Z","shell.execute_reply":"2022-03-13T11:57:02.854724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Approaches\n# 1) Bag of Words\n# 2) Word2Vec\n# 3) tfidf\n#  We will be using both Bag of Words and TF * IDF and will take the better one\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:57:02.856707Z","iopub.execute_input":"2022-03-13T11:57:02.856926Z","iopub.status.idle":"2022-03-13T11:57:02.861905Z","shell.execute_reply.started":"2022-03-13T11:57:02.8569Z","shell.execute_reply":"2022-03-13T11:57:02.860757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bag of Words Model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features=5000,stop_words='english')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:57:02.863386Z","iopub.execute_input":"2022-03-13T11:57:02.863615Z","iopub.status.idle":"2022-03-13T11:57:02.872689Z","shell.execute_reply.started":"2022-03-13T11:57:02.863583Z","shell.execute_reply":"2022-03-13T11:57:02.872038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectors=cv.fit_transform(new_movies_df['tags']).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:57:02.874199Z","iopub.execute_input":"2022-03-13T11:57:02.874481Z","iopub.status.idle":"2022-03-13T11:57:03.379504Z","shell.execute_reply.started":"2022-03-13T11:57:02.874444Z","shell.execute_reply":"2022-03-13T11:57:03.378287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This will be a pretty saprse Matrix\nvectors.shape","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-13T12:01:27.031611Z","iopub.execute_input":"2022-03-13T12:01:27.032119Z","iopub.status.idle":"2022-03-13T12:01:27.038561Z","shell.execute_reply.started":"2022-03-13T12:01:27.032069Z","shell.execute_reply":"2022-03-13T12:01:27.037709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TF IDF\n\ntfIdfVectorizer=TfidfVectorizer(use_idf=True,max_features=5000,stop_words='english')\ntfIdf = tfIdfVectorizer.fit_transform(new_movies_df['tags'])\n# We will be using this vector, which is same as vectors\ndf = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\ndf = df.sort_values('TF-IDF', ascending=False)\nprint (df.head(25))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T11:57:03.388127Z","iopub.execute_input":"2022-03-13T11:57:03.388372Z","iopub.status.idle":"2022-03-13T11:57:03.786228Z","shell.execute_reply.started":"2022-03-13T11:57:03.388333Z","shell.execute_reply":"2022-03-13T11:57:03.785208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the Cosine distance in the bag of words and TF IDF Model to find the similarity\n\nfrom sklearn.metrics.pairwise import cosine_similarity ","metadata":{"execution":{"iopub.status.busy":"2022-03-13T12:03:30.510178Z","iopub.execute_input":"2022-03-13T12:03:30.510976Z","iopub.status.idle":"2022-03-13T12:03:30.515441Z","shell.execute_reply.started":"2022-03-13T12:03:30.510932Z","shell.execute_reply":"2022-03-13T12:03:30.514609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity_bow=cosine_similarity(vectors)\nsimilarity_tfidf=cosine_similarity(tfIdf)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T12:04:08.125553Z","iopub.execute_input":"2022-03-13T12:04:08.12599Z","iopub.status.idle":"2022-03-13T12:04:10.89291Z","shell.execute_reply.started":"2022-03-13T12:04:08.125955Z","shell.execute_reply":"2022-03-13T12:04:10.891924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distance of each Movie with Each Movie so shape will be n x n \nprint(similarity_bow.shape)\nprint(similarity_tfidf.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T12:04:58.615702Z","iopub.execute_input":"2022-03-13T12:04:58.615979Z","iopub.status.idle":"2022-03-13T12:04:58.621063Z","shell.execute_reply.started":"2022-03-13T12:04:58.615949Z","shell.execute_reply":"2022-03-13T12:04:58.620118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Recommendation Function (Final):","metadata":{}},{"cell_type":"code","source":"# How to not loose index while sorting\n# Call the enumerate Function\nprint(sorted(list(enumerate(similarity_bow[0])),reverse=True,key=lambda x:x[1])[1:11])\nprint(sorted(list(enumerate(similarity_tfidf[0])),reverse=True,key=lambda x:x[1])[1:11])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-13T12:42:54.205237Z","iopub.execute_input":"2022-03-13T12:42:54.206179Z","iopub.status.idle":"2022-03-13T12:42:54.220347Z","shell.execute_reply.started":"2022-03-13T12:42:54.206129Z","shell.execute_reply":"2022-03-13T12:42:54.218935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommend(movie):\n    # Fetch the Index from the Similarity Array\n    # Then sort the distances in descending order of that index and return the top5 \n    # They will be the most similar movies to the  given Movie\n    movie_index=new_movies_df[new_movies_df['title']==movie].index[0]\n    distances_bow=similarity_bow[movie_index]\n    distances_tfidf=similarity_tfidf[movie_index]\n    movies_list_bow=sorted(list(enumerate(distances_bow)),reverse=True,key=lambda x:x[1])[1:11]\n    movies_list_tfidf=sorted(list(enumerate(distances_tfidf)),reverse=True,key=lambda x:x[1])[1:11]\n    print(\"Movies recommended by Bag of Words Method\")\n    for i in movies_list_bow:\n        \n        #print(i[0])\n        print(new_movies_df.iloc[i[0]].title)\n    print(\"Movies recommended by TF-IDF\")\n    for i in movies_list_tfidf:\n        \n        #print(i[0])\n        print(new_movies_df.iloc[i[0]].title)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T12:55:56.022239Z","iopub.execute_input":"2022-03-13T12:55:56.023232Z","iopub.status.idle":"2022-03-13T12:55:56.031403Z","shell.execute_reply.started":"2022-03-13T12:55:56.023179Z","shell.execute_reply":"2022-03-13T12:55:56.030593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommend('Batman Begins')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T12:58:30.100924Z","iopub.execute_input":"2022-03-13T12:58:30.101198Z","iopub.status.idle":"2022-03-13T12:58:30.120569Z","shell.execute_reply.started":"2022-03-13T12:58:30.10117Z","shell.execute_reply":"2022-03-13T12:58:30.118247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Collaborative Filtering ","metadata":{}},{"cell_type":"markdown","source":"### Building a Collaborative Filtering Recommender System on the Same Topic of Movie Recommendation ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}