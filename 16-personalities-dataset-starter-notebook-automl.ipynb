{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> The 16 Personalities Dataset: By Anshul </center>\n\n\n#### Link to the Dataset:\n#### [Dataset](https://www.kaggle.com/datasets/anshulmehtakaggl/60k-responses-of-16-personalities-test-mbt)\n<img src='https://i.pinimg.com/originals/a8/9f/5f/a89f5ff47344c8329e54706767eac545.jpg' >\n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-06T16:05:55.161521Z","iopub.execute_input":"2022-05-06T16:05:55.161905Z","iopub.status.idle":"2022-05-06T16:05:55.199530Z","shell.execute_reply.started":"2022-05-06T16:05:55.161784Z","shell.execute_reply":"2022-05-06T16:05:55.198662Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\ntrain_data=pd.read_csv('../input/60k-responses-of-16-personalities-test-mbt/16P.csv',encoding='cp1252')\ntrain_data=train_data.drop(columns={'Response Id'})\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:05:55.201421Z","iopub.execute_input":"2022-05-06T16:05:55.201728Z","iopub.status.idle":"2022-05-06T16:05:56.797330Z","shell.execute_reply.started":"2022-05-06T16:05:55.201687Z","shell.execute_reply":"2022-05-06T16:05:56.795732Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install pycaret","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-06T16:05:56.798921Z","iopub.execute_input":"2022-05-06T16:05:56.799652Z","iopub.status.idle":"2022-05-06T16:06:40.380733Z","shell.execute_reply.started":"2022-05-06T16:05:56.799614Z","shell.execute_reply":"2022-05-06T16:06:40.379874Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX=train_data.drop(columns=\"Personality\")\ny=train_data[\"Personality\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:06:40.383523Z","iopub.execute_input":"2022-05-06T16:06:40.383818Z","iopub.status.idle":"2022-05-06T16:06:40.540406Z","shell.execute_reply.started":"2022-05-06T16:06:40.383781Z","shell.execute_reply":"2022-05-06T16:06:40.539348Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Standardizing the features\nX = StandardScaler().fit_transform(X)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=21)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['pc1', 'pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11','pc12','pc13','pc14','pc15','pc16','pc17','pc18','pc19','pc20','pc21'])\nfinalDf = pd.concat([principalDf, train_data[['Personality']]], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:06:40.541713Z","iopub.execute_input":"2022-05-06T16:06:40.541965Z","iopub.status.idle":"2022-05-06T16:06:41.626171Z","shell.execute_reply.started":"2022-05-06T16:06:40.541939Z","shell.execute_reply":"2022-05-06T16:06:41.625122Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"finalDf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:06:41.627891Z","iopub.execute_input":"2022-05-06T16:06:41.628564Z","iopub.status.idle":"2022-05-06T16:06:41.660163Z","shell.execute_reply.started":"2022-05-06T16:06:41.628514Z","shell.execute_reply":"2022-05-06T16:06:41.659326Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from pycaret.classification import *\n#df = pd.read_csv(\"../input/60k-responses-of-16-personalities-test-mbt/16_Personalities_v1.csv\")\n\nclf = setup(\n    data=finalDf,\n    target=\"Personality\",\n    remove_multicollinearity=True,\n    remove_outliers=True,\n    remove_perfect_collinearity=True,\n    fix_imbalance=True,\n    log_experiment=True,\n    normalize=True,\n    transformation=True,\n    verbose=True,\n    silent=True,\n    feature_interaction=True,\n    feature_selection=True,\n    pca=True\n)\n%time best_model = compare_models()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T16:06:41.661510Z","iopub.execute_input":"2022-05-06T16:06:41.662013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport optuna.integration.lightgbm as lgb\nimport pandas as pd\nfrom lightgbm import early_stopping, log_evaluation\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\n\ndef objective(trial: optuna.Trial):\n#     df = pd.read_csv(\"../input/60k-responses-of-16-personalities-test-mbt/16_PERSONALITIES.csv\",encoding='cp1252')\n\n    train_x, test_x, train_y, test_y = train_test_split(\n        finalDf.drop(columns=\"Personality\"), finalDf[\"Personality\"], test_size=0.2\n    )\n\n    params = {\n        \"metric\": \"auc\",\n        \"objective\": \"binary\",\n        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 100),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n\n    dtrain = lgb.Dataset(train_x, label=train_y)\n    dval = lgb.Dataset(test_x, label=test_y)\n\n    model = lgb.train(\n        params,\n        dtrain,\n        valid_sets=[dtrain, dval],\n        callbacks=[early_stopping(100), log_evaluation(100)],\n    )\n\n    prediction = model.predict(test_x, num_iteration=model.best_iteration)\n    return roc_auc_score(test_y, prediction)\n\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_jobs=-1, n_trials=100)\nprint(study.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}