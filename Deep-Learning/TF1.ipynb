{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD_3kjBDf7mQ"
      },
      "source": [
        "The first Notebook on Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ejuVYyTkkrg"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
        "y=np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
        "X=tf.constant(X)\n",
        "y=tf.constant(y)"
      ],
      "metadata": {
        "id": "3JjYlAKTiggb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqeX6_lWlnGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf80b1fe-1dd5-4d20-f3ab-3dd8b655238a"
      },
      "source": [
        "# Housing Price Prediction With Tensors and Neural Networks \n",
        "# Creating a sample tensor for Housing price prediction\n",
        "house_info=tf.constant([\"bedrooms\",\"bathrooms\",\"garages\"])\n",
        "house_price=tf.constant([939700])\n",
        "house_info,house_price\n",
        "# Output gives the shape of the tensors\n",
        "# (<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedrooms', b'bathrooms', b'garages'], dtype=object)>,\n",
        "#  <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedrooms', b'bathrooms', b'garages'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a numpy array to tf by just passing it as a param in tf.constant\n",
        "# Modelling Steps \n",
        "tf.random.set_seed(42)\n",
        "# The good news is that by carefully setting the random seed across your pipeline you can achieve reproducibility.\n",
        "# The “seed” is a starting point for the sequence and the guarantee is that if you start from the same seed you will get the same sequence\n",
        "# of numbers. That said, you also want to test your experiments across different seed values.\n",
        "# Create a Sequential Model\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Because 1 Shaped ip and 1 shaped op\n",
        "\n",
        "# Compile \n",
        "# Loss function here is surronding the mean absolute error\n",
        "# The Mean Absolute Error(MAE) is the average of all absolute errors. The formula is: Sum of (Prediction-True Value)/n\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(),metrics=[\"mae\"])\n",
        "# Stochastic gradient descent is an iterative method for optimizing an objective function with suitable smoothness properties. \n",
        "# Optimizer around SGD\n",
        "\n",
        "# Model Fitting with the fix in dim expansion for shapes\n",
        "model.fit(tf.expand_dims(X, axis=-1),y,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uQeoQZveXlf",
        "outputId": "413719c5-b529-43dd-e11e-847cb0473194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bb73b6d10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output \n",
        "\n",
        "Epoch 1/5\n",
        "1/1 [==============================] - 0s 443ms/step - loss: 11.5048 - mae: 11.5048\n",
        "\n",
        "Epoch 2/5\n",
        "1/1 [==============================] - 0s 7ms/step - loss: 11.3723 - mae: 11.3723\n",
        "\n",
        "Epoch 3/5\n",
        "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
        "\n",
        "Epoch 4/5\n",
        "1/1 [==============================] - 0s 10ms/step - loss: 11.1073 - mae: 11.1073\n",
        "\n",
        "Epoch 5/5\n",
        "1/1 [==============================] - 0s 5ms/step - loss: 10.9748 - mae: 10.9748\n",
        "\n",
        "<keras.callbacks.History at 0x7f2bb753bb50>"
      ],
      "metadata": {
        "id": "HXU73mftkAZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict=model.predict([17.0])\n",
        "# Loss Function 11 no che\n",
        "y_predict+11\n",
        "# Even then it is far away from 27\n",
        "# Epcohs is the number of iterations the model will go through the training data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNp7z77_m23d",
        "outputId": "ae463eb3-c56d-40b9-e20c-a5393b17eb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improve the model <br>\n",
        "Increase the Layers <br>\n",
        "Increase the hiddenn units or Neurons <br>\n",
        "Change the activation Function <br>\n",
        "\n",
        "<b>While Comipiling </b>\n",
        "\n",
        "Chabge the learning rate <br>\n",
        "Change the Optimization Function<br>\n",
        "\n",
        "<b> Fitting </b>\n",
        "\n",
        "More epochs and Larger training Data\n",
        "\n"
      ],
      "metadata": {
        "id": "bJh4K5w2oJIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam optimizer involves a combination of two gradient descent methodologies: \n",
        "\n",
        "Momentum: \n",
        "\n",
        "This algorithm is used to accelerate the gradient descent algorithm by taking into consideration the ‘exponentially weighted average’ of the gradients. Using averages makes the algorithm converge towards the minima in a faster pace. \n",
        "\n",
        "\n",
        "\n",
        "Root Mean Square Propagation (RMSP): \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Root mean square prop or RMSprop is an adaptive learning algorithm that tries to improve AdaGrad. Instead of taking the cumulative sum of squared gradients like in AdaGrad, it takes the ‘exponential moving average’.\n",
        "\n"
      ],
      "metadata": {
        "id": "t4Nt3wosuuxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model=tf.keras.Sequential()\n",
        "# Adding 4 Layers\n",
        "# Adding 1st Layer\n",
        "model.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
        "# Adding 2nd Layer\n",
        "model.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
        "# Adding 3rd Layer\n",
        "model.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
        "# Here the 100 represent the number of neurons \n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "# So increase in the Number of Layers and the number of neurons\n",
        "\n",
        "# Changes in compilation\n",
        "model.compile(loss=\"mae\",optimizer=tf.keras.optimizers.Adam(lr=0.01),metrics=\"mae\")\n",
        "# So there's a change in the optimizer where Adam is used with a lr --> Learning Rate which indicates how\n",
        "# hard the model is pushed to improve, higher lr the harder the model is pushed to it's boundaries\n",
        "\n",
        "# Fitting the model\n",
        "model.fit(tf.expand_dims(X,axis=-1),y,epochs=100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAK6tE1Zn8pT",
        "outputId": "6baad350-7387-4f30-f888-1793d5e25924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 433ms/step - loss: 13.0557 - mae: 13.0557\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5067 - mae: 10.5067\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5663 - mae: 7.5663\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1418 - mae: 4.1418\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2048 - mae: 5.2048\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8777 - mae: 4.8777\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8712 - mae: 3.8712\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1877 - mae: 4.1877\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9614 - mae: 3.9614\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6248 - mae: 3.6248\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7904 - mae: 3.7904\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0559 - mae: 4.0559\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7454 - mae: 3.7454\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3898 - mae: 3.3898\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5021 - mae: 3.5021\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9981 - mae: 3.9981\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5190 - mae: 3.5190\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0519 - mae: 3.0519\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2618 - mae: 3.2618\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2906 - mae: 3.2906\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8586 - mae: 2.8586\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4855 - mae: 2.4855\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7534 - mae: 2.7534\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4910 - mae: 2.4910\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8510 - mae: 1.8510\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9188 - mae: 1.9188\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0796 - mae: 2.0796\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4675 - mae: 1.4675\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0400 - mae: 1.0400\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4212 - mae: 1.4212\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9506 - mae: 0.9506\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7192 - mae: 1.7192\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2247 - mae: 1.2247\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1591 - mae: 1.1591\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6979 - mae: 1.6979\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1546 - mae: 1.1546\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9537 - mae: 0.9537\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0910 - mae: 1.0910\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6432 - mae: 0.6432\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8753 - mae: 0.8753\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5887 - mae: 0.5887\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7880 - mae: 0.7880\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7017 - mae: 0.7017\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4563 - mae: 0.4563\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5996 - mae: 0.5996\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3719 - mae: 0.3719\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5279 - mae: 0.5279\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3622 - mae: 0.3622\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1665 - mae: 0.1665\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2310 - mae: 0.2310\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1972 - mae: 0.1972\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2248 - mae: 0.2248\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5684 - mae: 0.5684\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2387 - mae: 0.2387\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0018 - mae: 1.0018\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0642 - mae: 1.0642\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2493 - mae: 0.2493\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5412 - mae: 1.5412\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0827 - mae: 2.0827\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6125 - mae: 1.6125\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4155 - mae: 0.4155\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4511 - mae: 1.4511\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9870 - mae: 1.9870\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8835 - mae: 1.8835\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1587 - mae: 1.1587\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1748 - mae: 1.1748\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4460 - mae: 1.4460\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7722 - mae: 0.7722\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9003 - mae: 0.9003\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3106 - mae: 1.3106\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8680 - mae: 0.8680\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7610 - mae: 0.7610\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0548 - mae: 1.0548\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5253 - mae: 0.5253\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8900 - mae: 0.8900\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1961 - mae: 1.1961\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9236 - mae: 0.9236\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2203 - mae: 0.2203\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6461 - mae: 0.6461\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4191 - mae: 0.4191\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7816 - mae: 0.7816\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8552 - mae: 0.8552\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2941 - mae: 0.2941\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0521 - mae: 1.0521\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2122 - mae: 1.2122\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5811 - mae: 0.5811\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7700 - mae: 0.7700\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0745 - mae: 1.0745\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6354 - mae: 0.6354\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5407 - mae: 0.5407\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7824 - mae: 0.7824\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2666 - mae: 0.2666\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6492 - mae: 0.6492\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6164 - mae: 0.6164\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3155 - mae: 0.3155\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6037 - mae: 0.6037\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2925 - mae: 0.2925\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7433 - mae: 0.7433\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9569 - mae: 0.9569\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5638 - mae: 0.5638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bb5442d10>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs thi pan farak padi sake che\n",
        "# Overfitting is happening\n",
        "y_pred=model.predict([17.0])\n",
        "y_pred\n",
        "# OP array([[28.267117]], dtype=float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2VvZc8bvne2",
        "outputId": "e9d9a29b-a063-4ffa-cb9c-c906d9e76eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2bb536ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[28.267117]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the Model\n",
        "# Build --> Compile --> Fit --> Evaluate --> Tweak --> Fit --> Evaluate --> Tweak and the cycle goes so on\n",
        "# Visualization is the Most important thing while evaluation model\n",
        "# Visualize the Model and the training and the prediction\n",
        "X=tf.range(-100,100,4)\n",
        "X\n",
        "# Creating new Data Set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paN2A4z-x42K",
        "outputId": "9b396b3d-cf07-4172-cfcc-b35e664323d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=X+10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VqrQIFUC0az",
        "outputId": "9f7f22b2-810c-4817-bba5-38194e2a5092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The three sets \n",
        "# Train --> 70-80% \n",
        "# Validation --> 10-15% tweaks are tested here\n",
        "# Test the remaining 10-15% data set\n",
        "len(X)\n",
        "# So Train Test only splitted here\n",
        "X_train=X[:40]\n",
        "X_test=X[40:]\n",
        "y_train=y[:40]\n",
        "y_test=y[40:]\n"
      ],
      "metadata": {
        "id": "x9fNmezXC9xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Neural Network for our Data\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compiling the Model \n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.Adam(lr=0.01),metrics=\"mae\")\n",
        "\n",
        "# Fitting the Model on the training Data\n",
        "model.fit(tf.expand_dims(X_train,axis=-1),y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v2AQ4XNEpZr",
        "outputId": "62a92aea-9d09-4913-9781-0dcb49e0f7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 45.0037 - mae: 45.0037\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.9745 - mae: 34.9745\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 25.7018 - mae: 25.7018\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.5150 - mae: 16.5150\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6639 - mae: 8.6639\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2892 - mae: 9.2892\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.0144 - mae: 10.0144\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5557 - mae: 9.5557\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3849 - mae: 7.3849\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2949 - mae: 7.2949\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4103 - mae: 8.4103\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8134 - mae: 7.8134\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5210 - mae: 6.5210\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.1424 - mae: 5.1424\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.4452 - mae: 4.4452\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5853 - mae: 5.5853\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5107 - mae: 5.5107\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.1321 - mae: 4.1321\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.0945 - mae: 4.0945\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.5616 - mae: 4.5616\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5909 - mae: 4.5909\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.1464 - mae: 4.1464\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9499 - mae: 3.9499\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.1875 - mae: 4.1875\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 4.0401 - mae: 4.0401\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.9554 - mae: 3.9554\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.9149 - mae: 3.9149\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7521 - mae: 3.7521\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.7731 - mae: 3.7731\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.9049 - mae: 3.9049\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8419 - mae: 3.8419\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6274 - mae: 3.6274\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6212 - mae: 3.6212\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7809 - mae: 3.7809\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7792 - mae: 3.7792\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.6335 - mae: 3.6335\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 3.4233 - mae: 3.4233\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3522 - mae: 3.3522\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4848 - mae: 3.4848\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.3184 - mae: 3.3184\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2633 - mae: 3.2633\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.2650 - mae: 3.2650\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2207 - mae: 3.2207\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.1628 - mae: 3.1628\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.1647 - mae: 3.1647\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2711 - mae: 3.2711\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1694 - mae: 3.1694\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0208 - mae: 3.0208\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9335 - mae: 2.9335\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.8728 - mae: 2.8728\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.9054 - mae: 2.9054\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.8919 - mae: 2.8919\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.7288 - mae: 2.7288\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7277 - mae: 2.7277\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.7082 - mae: 2.7082\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6545 - mae: 2.6545\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5534 - mae: 2.5534\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.4639 - mae: 2.4639\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.5232 - mae: 2.5232\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.5578 - mae: 2.5578\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.4875 - mae: 2.4875\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2879 - mae: 2.2879\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.3027 - mae: 2.3027\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.1395 - mae: 2.1395\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.0776 - mae: 2.0776\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2062 - mae: 2.2062\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0438 - mae: 2.0438\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.9774 - mae: 1.9774\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7750 - mae: 1.7750\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8079 - mae: 1.8079\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5526 - mae: 1.5526\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 1.5969 - mae: 1.5969\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4118 - mae: 1.4118\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.2446 - mae: 1.2446\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7019 - mae: 1.7019\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3243 - mae: 1.3243\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.4841 - mae: 1.4841\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6685 - mae: 2.6685\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4733 - mae: 1.4733\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8880 - mae: 0.8880\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9529 - mae: 0.9529\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.4445 - mae: 1.4445\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0279 - mae: 1.0279\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4838 - mae: 1.4838\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6449 - mae: 1.6449\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9915 - mae: 0.9915\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5819 - mae: 1.5819\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0977 - mae: 2.0977\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.0668 - mae: 3.0668\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7677 - mae: 0.7677\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1598 - mae: 1.1598\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6536 - mae: 1.6536\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9217 - mae: 1.9217\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8329 - mae: 0.8329\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.0288 - mae: 1.0288\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0460 - mae: 1.0460\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8704 - mae: 0.8704\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9578 - mae: 0.9578\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4460 - mae: 0.4460\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0238 - mae: 1.0238\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2baf190e50>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the Splittes Test Data\n",
        "y_predict=model.predict([X_test])\n",
        "# Check the difference between the y_predict and y_test values here\n",
        "y_test,y_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mtxoRhnF7zc",
        "outputId": "addf6020-1489-4cdb-a6d2-df0c033ac74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>,)\n",
            "Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>,\n",
              " array([[ 67.7049  ],\n",
              "        [ 71.57828 ],\n",
              "        [ 75.4547  ],\n",
              "        [ 79.3311  ],\n",
              "        [ 83.207504],\n",
              "        [ 87.08392 ],\n",
              "        [ 90.960335],\n",
              "        [ 94.83675 ],\n",
              "        [ 98.71315 ],\n",
              "        [102.58957 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to automatically build a model with Input shape\n",
        "tf.random.set_seed(42)\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(9,input_shape=[1]))\n",
        "model.add(tf.keras.layers.Dense(1,input_shape=[1]))\n",
        "# Passing one number as input to get one value has Output here\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.SGD(),metrics=\"mae\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XzeJXjgjGsU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "# By specifying the IP Shape we have a Automatic build of the Model without even building it in the previous cell\n",
        "#  Non trainable params arennt updated during the training. They arise when we bring in already learne patterns \n",
        "# or parameters from other Models during Transfer Learning "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjgqIiTSHkAx",
        "outputId": "fc0dfd77-15a3-4348-cf96-c959a23b9442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_47 (Dense)            (None, 9)                 18        \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 1)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28\n",
            "Trainable params: 28\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Weights and Biases\n",
        "# MITs Intro to Deep Learning \n",
        "# Also learn what are trainable Params,\n",
        "# 1 Layer of 9 + 1 Layer of 1 \n",
        "model.fit(tf.expand_dims(X_train,axis=-1),y_train,epochs=100,verbose=2)\n",
        "# Verbose tells the progress of the model , 0 --> Silent , 1--> Interactive, Progress Bar, 2--> Non Interactive one line per epoch\n"
      ],
      "metadata": {
        "id": "gffx-WdhHuOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b29478-c84d-4e9a-aad7-1cf7d86976f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 - 0s - loss: 25.8250 - mae: 25.8250 - 280ms/epoch - 140ms/step\n",
            "Epoch 2/100\n",
            "2/2 - 0s - loss: 24.3820 - mae: 24.3820 - 4ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "2/2 - 0s - loss: 29.1371 - mae: 29.1371 - 3ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "2/2 - 0s - loss: 20.3640 - mae: 20.3640 - 4ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "2/2 - 0s - loss: 13.6997 - mae: 13.6997 - 4ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "2/2 - 0s - loss: 11.0246 - mae: 11.0246 - 4ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "2/2 - 0s - loss: 12.0272 - mae: 12.0272 - 4ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "2/2 - 0s - loss: 10.8640 - mae: 10.8640 - 3ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "2/2 - 0s - loss: 37.5767 - mae: 37.5767 - 4ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "2/2 - 0s - loss: 25.2322 - mae: 25.2322 - 3ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "2/2 - 0s - loss: 10.2423 - mae: 10.2423 - 4ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "2/2 - 0s - loss: 25.4007 - mae: 25.4007 - 4ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "2/2 - 0s - loss: 16.8407 - mae: 16.8407 - 3ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "2/2 - 0s - loss: 25.6591 - mae: 25.6591 - 6ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "2/2 - 0s - loss: 17.5313 - mae: 17.5313 - 4ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "2/2 - 0s - loss: 10.0286 - mae: 10.0286 - 3ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "2/2 - 0s - loss: 18.5527 - mae: 18.5527 - 205ms/epoch - 102ms/step\n",
            "Epoch 18/100\n",
            "2/2 - 0s - loss: 11.7249 - mae: 11.7249 - 3ms/epoch - 1ms/step\n",
            "Epoch 19/100\n",
            "2/2 - 0s - loss: 16.3733 - mae: 16.3733 - 3ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "2/2 - 0s - loss: 8.2406 - mae: 8.2406 - 4ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "2/2 - 0s - loss: 14.4532 - mae: 14.4532 - 8ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "2/2 - 0s - loss: 12.8734 - mae: 12.8734 - 5ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "2/2 - 0s - loss: 15.5021 - mae: 15.5021 - 4ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "2/2 - 0s - loss: 15.2934 - mae: 15.2934 - 3ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "2/2 - 0s - loss: 14.3530 - mae: 14.3530 - 5ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "2/2 - 0s - loss: 19.3766 - mae: 19.3766 - 4ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "2/2 - 0s - loss: 11.4255 - mae: 11.4255 - 6ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "2/2 - 0s - loss: 28.9932 - mae: 28.9932 - 4ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "2/2 - 0s - loss: 9.2415 - mae: 9.2415 - 5ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "2/2 - 0s - loss: 29.7551 - mae: 29.7551 - 4ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "2/2 - 0s - loss: 53.9789 - mae: 53.9789 - 4ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "2/2 - 0s - loss: 9.5416 - mae: 9.5416 - 5ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "2/2 - 0s - loss: 12.1308 - mae: 12.1308 - 5ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "2/2 - 0s - loss: 23.8105 - mae: 23.8105 - 4ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "2/2 - 0s - loss: 12.6284 - mae: 12.6284 - 6ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "2/2 - 0s - loss: 21.5606 - mae: 21.5606 - 4ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "2/2 - 0s - loss: 11.3427 - mae: 11.3427 - 6ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "2/2 - 0s - loss: 13.4128 - mae: 13.4128 - 6ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "2/2 - 0s - loss: 10.7596 - mae: 10.7596 - 5ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "2/2 - 0s - loss: 16.5347 - mae: 16.5347 - 4ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "2/2 - 0s - loss: 10.9347 - mae: 10.9347 - 4ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "2/2 - 0s - loss: 9.2710 - mae: 9.2710 - 3ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "2/2 - 0s - loss: 9.5784 - mae: 9.5784 - 3ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "2/2 - 0s - loss: 27.9230 - mae: 27.9230 - 4ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "2/2 - 0s - loss: 11.2568 - mae: 11.2568 - 5ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "2/2 - 0s - loss: 13.8606 - mae: 13.8606 - 5ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "2/2 - 0s - loss: 11.9128 - mae: 11.9128 - 9ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "2/2 - 0s - loss: 16.9436 - mae: 16.9436 - 5ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "2/2 - 0s - loss: 9.7711 - mae: 9.7711 - 5ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "2/2 - 0s - loss: 14.1691 - mae: 14.1691 - 7ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "2/2 - 0s - loss: 11.7316 - mae: 11.7316 - 6ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "2/2 - 0s - loss: 31.4273 - mae: 31.4273 - 6ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "2/2 - 0s - loss: 14.7380 - mae: 14.7380 - 5ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "2/2 - 0s - loss: 24.6450 - mae: 24.6450 - 6ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "2/2 - 0s - loss: 23.9290 - mae: 23.9290 - 6ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "2/2 - 0s - loss: 11.1224 - mae: 11.1224 - 7ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "2/2 - 0s - loss: 13.0673 - mae: 13.0673 - 6ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "2/2 - 0s - loss: 9.7820 - mae: 9.7820 - 5ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "2/2 - 0s - loss: 13.2548 - mae: 13.2548 - 5ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "2/2 - 0s - loss: 10.8384 - mae: 10.8384 - 5ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "2/2 - 0s - loss: 13.4310 - mae: 13.4310 - 7ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "2/2 - 0s - loss: 17.4324 - mae: 17.4324 - 4ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "2/2 - 0s - loss: 9.1392 - mae: 9.1392 - 4ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "2/2 - 0s - loss: 18.3082 - mae: 18.3082 - 4ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "2/2 - 0s - loss: 10.0951 - mae: 10.0951 - 6ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "2/2 - 0s - loss: 24.1608 - mae: 24.1608 - 3ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "2/2 - 0s - loss: 10.8545 - mae: 10.8545 - 4ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "2/2 - 0s - loss: 10.7447 - mae: 10.7447 - 5ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "2/2 - 0s - loss: 23.1494 - mae: 23.1494 - 5ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "2/2 - 0s - loss: 8.8283 - mae: 8.8283 - 5ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "2/2 - 0s - loss: 16.0478 - mae: 16.0478 - 5ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "2/2 - 0s - loss: 7.7424 - mae: 7.7424 - 5ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "2/2 - 0s - loss: 10.1529 - mae: 10.1529 - 5ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "2/2 - 0s - loss: 28.3243 - mae: 28.3243 - 6ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "2/2 - 0s - loss: 10.0113 - mae: 10.0113 - 5ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "2/2 - 0s - loss: 12.9292 - mae: 12.9292 - 6ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "2/2 - 0s - loss: 17.9156 - mae: 17.9156 - 6ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "2/2 - 0s - loss: 8.9594 - mae: 8.9594 - 5ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "2/2 - 0s - loss: 28.7569 - mae: 28.7569 - 6ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "2/2 - 0s - loss: 31.1006 - mae: 31.1006 - 4ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "2/2 - 0s - loss: 13.4381 - mae: 13.4381 - 5ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "2/2 - 0s - loss: 14.3098 - mae: 14.3098 - 5ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "2/2 - 0s - loss: 18.8408 - mae: 18.8408 - 4ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "2/2 - 0s - loss: 9.4534 - mae: 9.4534 - 4ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "2/2 - 0s - loss: 25.2358 - mae: 25.2358 - 5ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "2/2 - 0s - loss: 16.4553 - mae: 16.4553 - 4ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "2/2 - 0s - loss: 11.4716 - mae: 11.4716 - 5ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "2/2 - 0s - loss: 27.0837 - mae: 27.0837 - 5ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "2/2 - 0s - loss: 9.7436 - mae: 9.7436 - 4ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "2/2 - 0s - loss: 19.1182 - mae: 19.1182 - 5ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "2/2 - 0s - loss: 10.6054 - mae: 10.6054 - 4ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "2/2 - 0s - loss: 18.3354 - mae: 18.3354 - 5ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "2/2 - 0s - loss: 6.8585 - mae: 6.8585 - 6ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "2/2 - 0s - loss: 13.0888 - mae: 13.0888 - 5ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "2/2 - 0s - loss: 18.4903 - mae: 18.4903 - 5ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "2/2 - 0s - loss: 10.4167 - mae: 10.4167 - 5ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "2/2 - 0s - loss: 14.4875 - mae: 14.4875 - 4ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "2/2 - 0s - loss: 6.6161 - mae: 6.6161 - 4ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "2/2 - 0s - loss: 12.6107 - mae: 12.6107 - 5ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "2/2 - 0s - loss: 19.4145 - mae: 19.4145 - 5ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2baf0782d0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some more Visualizations\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model=model,show_shapes=True)\n",
        "# IP to Layer 1 ma 9 connections , 9 Layer to 1 Layer waala ma bija 9 connections and +2 IP OP waal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "D1ZhVSnxUlaK",
        "outputId": "4d950f7d-c39d-4088-a758-ee9f55282e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Also we can name the layers subsequently \n"
      ],
      "metadata": {
        "id": "El-RaQ6JWn-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
